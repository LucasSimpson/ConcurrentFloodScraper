# Concurrent Flood Scraper

## It's probably exactly what you think it is, based off the name


GET a page. scrape for urls, filter those according to some regex. Put all those in a master queue. Scrape page for any data you want. Repeat...

There's a small demo in the wikipedia_parser_demo. There you can see how easy it is to set up to fit your web scraping needs!

